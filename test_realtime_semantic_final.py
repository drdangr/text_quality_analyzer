#!/usr/bin/env python3
"""
–§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ Realtime API
"""

import asyncio
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from analysis.semantic_function_realtime import SemanticRealtimeAnalyzer, RealtimeSessionConfig
from dotenv import load_dotenv

load_dotenv()

async def test_semantic_analysis():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π"""
    api_key = os.getenv("OPENAI_API_KEY")
    
    print("üöÄ –§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –ê–ù–ê–õ–ò–ó–ê –ß–ï–†–ï–ó REALTIME API")
    print("=" * 60)
    
    analyzer = SemanticRealtimeAnalyzer(api_key=api_key)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é —Å —Ç–µ–º–æ–π
        config = RealtimeSessionConfig(
            topic="–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
            temperature=0.6  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        )
        
        print(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
        print(f"   –¢–µ–º–∞: {config.topic}")
        print(f"   –ú–æ–¥–µ–ª—å: {config.model}")
        print(f"   –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {config.temperature}")
        print()
        
        await analyzer.initialize_session(config)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ —á–∞–Ω–∫–∏ —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ —Ä–æ–ª—è–º–∏
        test_chunks = [
            {
                "id": "1",
                "text": "–ò–ò —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É–µ—Ç –º–∏—Ä —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π, –æ—Ç–∫—Ä—ã–≤–∞—è –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏.",
                "expected": "—Ä–∞—Å–∫—Ä—ã—Ç–∏–µ —Ç–µ–º—ã"
            },
            {
                "id": "2", 
                "text": "–ö–∞–∫ —É—Ç—Ä–µ–Ω–Ω–∏–π –∫–æ—Ñ–µ –ø—Ä–æ–±—É–∂–¥–∞–µ—Ç —Å–æ–∑–Ω–∞–Ω–∏–µ, —Ç–∞–∫ –∏ –ò–ò –ø—Ä–æ–±—É–∂–¥–∞–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞.",
                "expected": "–º–µ—Ç–∞—Ñ–æ—Ä–∞ –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—è"
            },
            {
                "id": "3",
                "text": "–í—á–µ—Ä–∞ —è –µ–ª –ø–∏—Ü—Ü—É —Å –∞–Ω–∞–Ω–∞—Å–∞–º–∏.",
                "expected": "—à—É–º"
            },
            {
                "id": "4",
                "text": "–ù–∞–ø—Ä–∏–º–µ—Ä, ChatGPT –ø–æ–º–æ–≥–∞–µ—Ç –º–∏–ª–ª–∏–æ–Ω–∞–º –ª—é–¥–µ–π —Ä–µ—à–∞—Ç—å –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏.",
                "expected": "–ø–æ—è—Å–Ω–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ"
            },
            {
                "id": "5",
                "text": "–ò–ò - —ç—Ç–æ –∫–ª—é—á –∫ –±—É–¥—É—â–µ–º—É —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞.",
                "expected": "–∫–ª—é—á–µ–≤–æ–π —Ç–µ–∑–∏—Å"
            },
            {
                "id": "6",
                "text": "–ö–æ–Ω–µ—á–Ω–æ, –ò–ò –Ω–∞—Å—Ç–æ–ª—å–∫–æ —É–º—ë–Ω, —á—Ç–æ —Å–∫–æ—Ä–æ –±—É–¥–µ—Ç –ø–∏—Å–∞—Ç—å —Å—Ç–∏—Ö–∏ –ª—É—á—à–µ –ü—É—à–∫–∏–Ω–∞!",
                "expected": "—é–º–æ—Ä –∏–ª–∏ –∏—Ä–æ–Ω–∏—è –∏–ª–∏ —Å–∞—Ä–∫–∞–∑–º"
            },
            {
                "id": "7",
                "text": "–ê —Ç–µ–ø–µ—Ä—å –ø–æ–≥–æ–≤–æ—Ä–∏–º –æ –¥—Ä—É–≥–æ–π –≤–∞–∂–Ω–æ–π —Ç–µ–º–µ - –∫–≤–∞–Ω—Ç–æ–≤—ã—Ö –∫–æ–º–ø—å—é—Ç–µ—Ä–∞—Ö.",
                "expected": "—Å–º–µ–Ω–∞ —Ç–µ–º—ã"
            }
        ]
        
        print(f"üìù –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(test_chunks)} —Ç–µ—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤...")
        print()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞–Ω–∫–∏
        chunks_for_analysis = [{"id": chunk["id"], "text": chunk["text"]} for chunk in test_chunks]
        results = await analyzer.analyze_batch(chunks_for_analysis)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print("-" * 60)
        
        correct_count = 0
        for test_chunk, result in zip(test_chunks, results):
            chunk_id = test_chunk["id"]
            text_preview = test_chunk["text"][:50] + "..." if len(test_chunk["text"]) > 50 else test_chunk["text"]
            expected = test_chunk["expected"]
            actual = result.get("semantic_function", "error")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–∂–∏–¥–∞–µ–º—É—é —Ä–æ–ª—å
            is_correct = expected in actual or actual in expected
            if actual not in ["error_timeout", "error_api_call", "parsing_error"]:
                correct_count += 1 if is_correct else 0
            
            status = "‚úÖ" if is_correct else "‚ùå"
            
            print(f"\n–ß–∞–Ω–∫ {chunk_id}: {text_preview}")
            print(f"  –û–∂–∏–¥–∞–ª–æ—Å—å: {expected}")
            print(f"  –ü–æ–ª—É—á–µ–Ω–æ:  {actual} {status}")
            
            if result.get("semantic_error"):
                print(f"  –û—à–∏–±–∫–∞: {result['semantic_error']}")
        
        print("\n" + "-" * 60)
        total_valid = len([r for r in results if r.get("semantic_function") not in ["error_timeout", "error_api_call", "parsing_error"]])
        if total_valid > 0:
            accuracy = (correct_count / total_valid) * 100
            print(f"üìà –¢–æ—á–Ω–æ—Å—Ç—å: {correct_count}/{total_valid} ({accuracy:.1f}%)")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        print("\n‚ö° –¢–ï–°–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
        print("-" * 60)
        
        import time
        start_time = time.time()
        
        perf_chunks = [
            {"id": f"perf_{i}", "text": f"–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç {i} –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ API."}
            for i in range(5)
        ]
        
        perf_results = await analyzer.analyze_batch(perf_chunks)
        elapsed = time.time() - start_time
        
        successful = len([r for r in perf_results if "error" not in r.get("semantic_function", "")])
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {successful}/{len(perf_chunks)} —á–∞–Ω–∫–æ–≤ –∑–∞ {elapsed:.2f} —Å–µ–∫")
        print(f"‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —á–∞–Ω–∫: {elapsed/len(perf_chunks):.2f} —Å–µ–∫")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        await analyzer.close()
        
    print("\n" + "=" * 60)
    print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == "__main__":
    asyncio.run(test_semantic_analysis()) 