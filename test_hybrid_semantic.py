#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback
"""

import asyncio
import time
import sys
import os
from typing import List, Dict
from dotenv import load_dotenv

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from analysis.semantic_function_hybrid import HybridSemanticAnalyzer, analyze_semantic_hybrid

load_dotenv()


async def test_single_chunk_with_fallback():
    """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ —Å –∏–º–∏—Ç–∞—Ü–∏–µ–π –æ—à–∏–±–∫–∏ –∏ fallback"""
    print("\nüß™ –¢–ï–°–¢ 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ —Å fallback")
    print("=" * 60)
    
    api_key = os.getenv("OPENAI_API_KEY")
    analyzer = HybridSemanticAnalyzer(api_key=api_key)
    
    test_chunk = {
        "id": "test_1",
        "text": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É–µ—Ç –º–∏—Ä —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π."
    }
    topic = "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"
    
    try:
        # –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å - –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Realtime API
        start = time.time()
        result1 = await analyzer.analyze_chunk(
            chunk_id=test_chunk["id"],
            chunk_text=test_chunk["text"],
            topic=topic
        )
        time1 = time.time() - start
        
        print(f"‚úÖ –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å:")
        print(f"   –ú–µ—Ç–æ–¥: {result1['api_method']}")
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {result1['semantic_function']}")
        print(f"   –í—Ä–µ–º—è: {time1:.2f}—Å")
        
        # –ò–º–∏—Ç–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—à–∏–±–æ–∫ –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ fallback
        print("\nüîÑ –ò–º–∏—Ç–∞—Ü–∏—è –æ—à–∏–±–æ–∫ Realtime API...")
        for i in range(3):
            analyzer.failure_tracker.record_failure()
        
        # –í—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å - –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å REST API (fallback)
        start = time.time()
        result2 = await analyzer.analyze_chunk(
            chunk_id=f"test_2",
            chunk_text="–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - –±—É–¥—É—â–µ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è.",
            topic=topic
        )
        time2 = time.time() - start
        
        print(f"\n‚úÖ –í—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å (–ø–æ—Å–ª–µ –æ—à–∏–±–æ–∫):")
        print(f"   –ú–µ—Ç–æ–¥: {result2['api_method']}")
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {result2['semantic_function']}")
        print(f"   –í—Ä–µ–º—è: {time2:.2f}—Å")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = await analyzer.get_statistics()
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   Realtime –¥–æ—Å—Ç—É–ø–µ–Ω: {stats['realtime_available']}")
        print(f"   –û—à–∏–±–æ–∫: {stats['realtime_failures']}")
        print(f"   –£—Å–ø–µ—Ö–æ–≤: {stats['realtime_successes']}")
        
    finally:
        await analyzer.close()


async def test_batch_adaptive_strategy():
    """–¢–µ—Å—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    print("\n\nüß™ –¢–ï–°–¢ 2: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –ø–∞–∫–µ—Ç–∞")
    print("=" * 60)
    
    api_key = os.getenv("OPENAI_API_KEY")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —á–∞–Ω–∫–∏
    test_chunks = [
        {"id": f"chunk_{i}", "text": f"–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç {i} –ø—Ä–æ –ò–ò –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –±—É–¥—É—â–µ–≥–æ."}
        for i in range(15)
    ]
    topic = "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"
    
    analyzer = HybridSemanticAnalyzer(api_key=api_key)
    
    try:
        start = time.time()
        results = await analyzer.analyze_batch(
            chunks=test_chunks,
            topic=topic,
            adaptive_batching=True
        )
        total_time = time.time() - start
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        realtime_results = [r for r in results if r['api_method'] == 'realtime']
        rest_results = [r for r in results if r['api_method'] == 'rest']
        failed_results = [r for r in results if r['api_method'] == 'failed']
        
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} —á–∞–Ω–∫–æ–≤ –∑–∞ {total_time:.2f}—Å")
        print(f"   –ß–µ—Ä–µ–∑ Realtime API: {len(realtime_results)}")
        print(f"   –ß–µ—Ä–µ–∑ REST API: {len(rest_results)}")
        print(f"   –û—à–∏–±–æ–∫: {len(failed_results)}")
        
        if realtime_results:
            avg_realtime = sum(r.get('api_latency', 0) for r in realtime_results) / len(realtime_results)
            print(f"   –°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞ Realtime: {avg_realtime:.3f}—Å")
        
        # –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\nüìÑ –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        for i, result in enumerate(results[:3]):
            print(f"   {result['chunk_id']}: {result['semantic_function']} ({result['api_method']})")
            
    finally:
        await analyzer.close()


async def test_error_resilience():
    """–¢–µ—Å—Ç —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∫ –æ—à–∏–±–∫–∞–º"""
    print("\n\nüß™ –¢–ï–°–¢ 3: –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –æ—à–∏–±–∫–∞–º")
    print("=" * 60)
    
    api_key = os.getenv("OPENAI_API_KEY")
    analyzer = HybridSemanticAnalyzer(api_key=api_key)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–æ–±–ª–µ–º–Ω—ã–º–∏ —Ç–µ–∫—Å—Ç–∞–º–∏
    test_chunks = [
        {"id": "normal_1", "text": "–ò–ò —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –∏–Ω–¥—É—Å—Ç—Ä–∏—é."},
        {"id": "empty", "text": ""},  # –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
        {"id": "normal_2", "text": "–ù–µ–π—Ä–æ—Å–µ—Ç–∏ —É—á–∞—Ç—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö."},
        {"id": "long", "text": "–ê" * 5000},  # –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        {"id": "normal_3", "text": "–ë—É–¥—É—â–µ–µ –∑–∞ –º–∞—à–∏–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º."},
    ]
    topic = "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"
    
    try:
        results = await analyzer.analyze_batch(
            chunks=test_chunks,
            topic=topic,
            adaptive_batching=False  # –û—Ç–∫–ª—é—á–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤
        )
        
        print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —á–∞–Ω–∫–æ–≤:")
        for result in results:
            status = "‚úÖ" if result['semantic_function'] else "‚ùå"
            method = result['api_method']
            error = result.get('semantic_error', '')
            print(f"   {status} {result['chunk_id']}: {method} - {error if error else result['semantic_function']}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = await analyzer.get_statistics()
        print(f"\nüìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –°–µ—Å—Å–∏—è –∞–∫—Ç–∏–≤–Ω–∞: {stats['session_active']}")
        print(f"   –û—à–∏–±–æ–∫ Realtime: {stats['realtime_failures']}")
        print(f"   –£—Å–ø–µ—Ö–æ–≤ Realtime: {stats['realtime_successes']}")
        
    finally:
        await analyzer.close()


async def test_performance_comparison():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
    print("\n\nüß™ –¢–ï–°–¢ 4: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
    print("=" * 60)
    
    api_key = os.getenv("OPENAI_API_KEY")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_chunks = [
        {"id": f"perf_{i}", "text": f"–¢–µ–∫—Å—Ç {i} –ø—Ä–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –∏ –µ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ."}
        for i in range(10)
    ]
    topic = "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"
    
    # –¢–µ—Å—Ç 1: –¢–æ–ª—å–∫–æ REST API
    print("\n1Ô∏è‚É£ –¢–æ–ª—å–∫–æ REST API:")
    analyzer_rest = HybridSemanticAnalyzer(api_key=api_key, prefer_realtime=False)
    try:
        start = time.time()
        results = await analyzer_rest.analyze_batch(chunks=test_chunks, topic=topic)
        rest_time = time.time() - start
        rest_success = sum(1 for r in results if r['semantic_function'])
        print(f"   –í—Ä–µ–º—è: {rest_time:.2f}—Å")
        print(f"   –£—Å–ø–µ—à–Ω–æ: {rest_success}/{len(test_chunks)}")
    finally:
        await analyzer_rest.close()
    
    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
    await asyncio.sleep(2)
    
    # –¢–µ—Å—Ç 2: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥
    print("\n2Ô∏è‚É£ –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (Realtime + REST):")
    analyzer_hybrid = HybridSemanticAnalyzer(api_key=api_key, prefer_realtime=True)
    try:
        start = time.time()
        results = await analyzer_hybrid.analyze_batch(
            chunks=test_chunks, 
            topic=topic,
            adaptive_batching=True
        )
        hybrid_time = time.time() - start
        hybrid_success = sum(1 for r in results if r['semantic_function'])
        
        realtime_count = sum(1 for r in results if r['api_method'] == 'realtime')
        rest_count = sum(1 for r in results if r['api_method'] == 'rest')
        
        print(f"   –í—Ä–µ–º—è: {hybrid_time:.2f}—Å")
        print(f"   –£—Å–ø–µ—à–Ω–æ: {hybrid_success}/{len(test_chunks)}")
        print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {realtime_count} Realtime, {rest_count} REST")
        
    finally:
        await analyzer_hybrid.close()
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
    print("\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ:")
    if hybrid_time < rest_time:
        speedup = rest_time / hybrid_time
        print(f"   ‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –±—ã—Å—Ç—Ä–µ–µ –≤ {speedup:.2f}x —Ä–∞–∑!")
    else:
        print(f"   ‚ÑπÔ∏è REST API –æ–∫–∞–∑–∞–ª—Å—è –±—ã—Å—Ç—Ä–µ–µ (–≤–æ–∑–º–æ–∂–Ω–æ, –∏–∑-–∑–∞ –ø–∞—É–∑ Realtime)")
    
    print(f"   –†–∞–∑–Ω–∏—Ü–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–∏: {abs(hybrid_time - rest_time):.2f}—Å")


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ì–ò–ë–†–ò–î–ù–û–ì–û –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –ê–ù–ê–õ–ò–ó–ê")
    print("=" * 60)
    print("–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –º–µ–∂–¥—É Realtime –∏ REST API")
    print("–¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏.")
    print("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã
    await test_single_chunk_with_fallback()
    await test_batch_adaptive_strategy()
    await test_error_resilience()
    await test_performance_comparison()
    
    print("\n" + "=" * 60)
    print("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –±–∞–ª–∞–Ω—Å–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏")
    print("- Realtime API –¥–∞–µ—Ç 4x —É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ –º–∞–ª—ã—Ö –æ–±—ä–µ–º–∞—Ö")
    print("- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fallback –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å")
    print("- –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –±–æ–ª—å—à–∏—Ö –ø–∞–∫–µ—Ç–æ–≤")


if __name__ == "__main__":
    asyncio.run(main()) 