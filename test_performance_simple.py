#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
"""

import asyncio
import time
import sys
import os
from dotenv import load_dotenv

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from analysis.semantic_function import analyze_semantic_function_batch
from analysis.semantic_function_realtime import SemanticRealtimeAnalyzer, RealtimeSessionConfig
from services.openai_service import OpenAIService

load_dotenv()

async def analyze_semantic_function_batch_wrapper(chunks, topic, max_concurrent=1):
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —á–∞–Ω–∫–æ–≤ —á–µ—Ä–µ–∑ REST API"""
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI service
    api_key = os.getenv("OPENAI_API_KEY")
    openai_service = OpenAIService(api_key=api_key)
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω—É–∂–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    from analysis.semantic_function import analyze_batch_chunks_semantic
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —á–∞–Ω–∫–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    full_text = "\n\n".join([chunk["text"] for chunk in chunks])
    
    # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∞–Ω–∞–ª–∏–∑–∞
    results = await analyze_batch_chunks_semantic(
        chunks=chunks,
        full_text=full_text,
        topic=topic,
        openai_service=openai_service,
        max_parallel=max_concurrent
    )
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    formatted_results = []
    for result in results:
        metrics = result.get("metrics", {})
        formatted_results.append({
            "chunk_id": result.get("chunk_id"),
            "semantic_function": metrics.get("semantic_function"),
            "semantic_method": metrics.get("semantic_method"),
            "semantic_error": metrics.get("semantic_error")
        })
    
    return formatted_results

async def test_rest_simple():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç REST API"""
    print("\nüîµ –¢–ï–°–¢ REST API")
    print("-" * 50)
    
    test_chunks = [
        {"id": "1", "text": "–ò–ò —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏."},
        {"id": "2", "text": "–í—á–µ—Ä–∞ —è –µ–ª –ø–∏—Ü—Ü—É."},
        {"id": "3", "text": "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - —ç—Ç–æ –±—É–¥—É—â–µ–µ."},
        {"id": "4", "text": "–ö–∞–∫ —É—Ç—Ä–µ–Ω–Ω–∏–π –∫–æ—Ñ–µ –ø—Ä–æ–±—É–∂–¥–∞–µ—Ç —Ä–∞–∑—É–º."},
        {"id": "5", "text": "GPT-4 - –ø—Ä–∏–º–µ—Ä —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ò–ò."}
    ]
    
    topic = "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"
    successful = 0
    total_time = 0
    
    for chunk in test_chunks:
        try:
            start = time.time()
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à—É –æ–±–µ—Ä—Ç–∫—É
            results = await analyze_semantic_function_batch_wrapper(
                chunks=[chunk],
                topic=topic,
                max_concurrent=1
            )
            elapsed = time.time() - start
            total_time += elapsed
            
            if results and len(results) > 0:
                result = results[0]
                if result.get("semantic_function") and "error" not in result.get("semantic_function", ""):
                    successful += 1
                    print(f"‚úÖ –ß–∞–Ω–∫ {chunk['id']}: {result['semantic_function']} ({elapsed:.2f}—Å)")
                else:
                    print(f"‚ùå –ß–∞–Ω–∫ {chunk['id']}: {result.get('semantic_error', 'Unknown error')}")
            else:
                print(f"‚ùå –ß–∞–Ω–∫ {chunk['id']}: –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è —á–∞–Ω–∫–∞ {chunk['id']}: {type(e).__name__}: {e}")
    
    print(f"\n–ò—Ç–æ–≥–æ: {successful}/{len(test_chunks)} —É—Å–ø–µ—à–Ω–æ")
    print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f}—Å")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {total_time/len(test_chunks):.2f}—Å/—á–∞–Ω–∫")

async def test_realtime_simple():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç Realtime API"""
    print("\nüü¢ –¢–ï–°–¢ REALTIME API")
    print("-" * 50)
    
    api_key = os.getenv("OPENAI_API_KEY")
    analyzer = SemanticRealtimeAnalyzer(api_key=api_key)
    
    test_chunks = [
        {"id": "1", "text": "–ò–ò —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏."},
        {"id": "2", "text": "–í—á–µ—Ä–∞ —è –µ–ª –ø–∏—Ü—Ü—É."},
        {"id": "3", "text": "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - —ç—Ç–æ –±—É–¥—É—â–µ–µ."},
        {"id": "4", "text": "–ö–∞–∫ —É—Ç—Ä–µ–Ω–Ω–∏–π –∫–æ—Ñ–µ –ø—Ä–æ–±—É–∂–¥–∞–µ—Ç —Ä–∞–∑—É–º."},
        {"id": "5", "text": "GPT-4 - –ø—Ä–∏–º–µ—Ä —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ò–ò."}
    ]
    
    successful = 0
    total_time = 0
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é
        config = RealtimeSessionConfig(
            topic="–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
            temperature=0.6
        )
        await analyzer.initialize_session(config)
        print("‚úÖ –°–µ—Å—Å–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ —Å –ø–∞—É–∑–æ–π –º–µ–∂–¥—É –Ω–∏–º–∏
        for chunk in test_chunks:
            try:
                start = time.time()
                result = await analyzer.analyze_chunk(
                    chunk_id=chunk["id"],
                    chunk_text=chunk["text"]
                )
                elapsed = time.time() - start
                total_time += elapsed
                
                if result.get("semantic_function") and "error" not in result.get("semantic_function", ""):
                    successful += 1
                    print(f"‚úÖ –ß–∞–Ω–∫ {chunk['id']}: {result['semantic_function']} ({elapsed:.2f}—Å)")
                else:
                    print(f"‚ùå –ß–∞–Ω–∫ {chunk['id']}: {result.get('semantic_error', 'Unknown error')}")
                
                # –í–∞–∂–Ω–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏!
                await asyncio.sleep(0.5)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è —á–∞–Ω–∫–∞ {chunk['id']}: {type(e).__name__}: {e}")
                
    except Exception as e:
        print(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞: {type(e).__name__}: {e}")
        
    finally:
        await analyzer.close()
        
    print(f"\n–ò—Ç–æ–≥–æ: {successful}/{len(test_chunks)} —É—Å–ø–µ—à–Ω–æ")
    print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f}—Å")
    if len(test_chunks) > 0:
        print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {total_time/len(test_chunks):.2f}—Å/—á–∞–Ω–∫")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –£–ü–†–û–©–ï–ù–ù–´–ô –¢–ï–°–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print("=" * 50)
    
    # –¢–µ—Å—Ç REST API
    await test_rest_simple()
    
    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
    await asyncio.sleep(2)
    
    # –¢–µ—Å—Ç Realtime API
    await test_realtime_simple()
    
    print("\n" + "=" * 50)
    print("‚úÖ –¢–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")

if __name__ == "__main__":
    asyncio.run(main()) 