#!/usr/bin/env python3
"""
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ä–æ–≥–æ –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–æ–≤ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
"""

import requests
import json
import time
from typing import List, Dict

API_BASE = "http://localhost:8000"

# –¢–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –ø—Ä–æ –∫–æ—Ä–æ–≤
TEST_TEXT = """–ö–æ—Ä–æ–≤—ã - —ç—Ç–æ –∫—Ä—É–ø–Ω—ã–µ –¥–æ–º–∞—à–Ω–∏–µ –∂–∏–≤–æ—Ç–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –¥–∞—é—Ç –º–æ–ª–æ–∫–æ. –û–Ω–∏ –∂–∏–≤—É—Ç –Ω–∞ —Ñ–µ—Ä–º–∞—Ö –∏ –ø–∞—Å—É—Ç—Å—è –Ω–∞ –ª—É–≥–∞—Ö.

–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ —Å–µ–±–µ –∫–æ—Ä–æ–≤—É —Ä–∞–∑–º–µ—Ä–æ–º —Å –∫–∏—Ç–∞ - –≤–æ—Ç —ç—Ç–æ –±—ã–ª–∞ –±—ã –º–æ–ª–æ—á–Ω–∞—è —Ñ–µ—Ä–º–∞! –ù–æ —ç—Ç–æ –∫–æ–Ω–µ—á–Ω–æ —à—É—Ç–∫–∞.

–í –¥—Ä–µ–≤–Ω–æ—Å—Ç–∏ –∫–æ—Ä–æ–≤—ã —Å—á–∏—Ç–∞–ª–∏—Å—å —Å–≤—è—â–µ–Ω–Ω—ã–º–∏ –∂–∏–≤–æ—Ç–Ω—ã–º–∏ –≤–æ –º–Ω–æ–≥–∏—Ö –∫—É–ª—å—Ç—É—Ä–∞—Ö. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –ò–Ω–¥–∏–∏ –∫–æ—Ä–æ–≤–∞ –¥–æ —Å–∏—Ö –ø–æ—Ä —è–≤–ª—è–µ—Ç—Å—è —Å–≤—è—â–µ–Ω–Ω—ã–º –∂–∏–≤–æ—Ç–Ω—ã–º.

–ú–æ–ª–æ–∫–æ –∫–æ—Ä–æ–≤—ã —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø–æ–ª–µ–∑–Ω—ã—Ö –≤–µ—â–µ—Å—Ç–≤: –±–µ–ª–∫–∏, –∂–∏—Ä—ã, –∫–∞–ª—å—Ü–∏–π, –≤–∏—Ç–∞–º–∏–Ω—ã.

–ê –≤—á–µ—Ä–∞ —è –≤–∏–¥–µ–ª, –∫–∞–∫ –∫–æ—Ä–æ–≤–∞ –ø–µ—Ä–µ–ø—Ä—ã–≥–Ω—É–ª–∞ —á–µ—Ä–µ–∑ –ª—É–Ω—É. –®—É—á—É, –∫–æ–Ω–µ—á–Ω–æ, —ç—Ç–æ –∏–∑ –¥–µ—Ç—Å–∫–æ–π –ø–µ—Å–µ–Ω–∫–∏.

–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç: –æ–¥–Ω–∞ –∫–æ—Ä–æ–≤–∞ –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å –¥–æ 30 –ª–∏—Ç—Ä–æ–≤ –º–æ–ª–æ–∫–∞ –≤ –¥–µ–Ω—å.

–ö–æ—Ä–æ–≤—ã –æ–±—â–∞—é—Ç—Å—è –º–µ–∂–¥—É —Å–æ–±–æ–π —Å –ø–æ–º–æ—â—å—é –º—ã—á–∞–Ω–∏—è. –£ –Ω–∏—Ö –µ—Å—Ç—å —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –º—ã—á–∞–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π.

–í —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –º–∏—Ä–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø–æ—Ä–æ–¥ –∫–æ—Ä–æ–≤, –∫–∞–∂–¥–∞—è —Å–æ —Å–≤–æ–∏–º–∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è–º–∏."""

def create_test_chunks(text: str) -> List[Dict]:
    """–°–æ–∑–¥–∞–µ—Ç —á–∞–Ω–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–∞–º —Å—Ç—Ä–æ–∫"""
    chunks = []
    paragraphs = text.split('\n\n')
    current_pos = 0
    
    for i, paragraph in enumerate(paragraphs):
        if paragraph.strip():
            start = text.find(paragraph, current_pos)
            end = start + len(paragraph)
            chunks.append({
                "id": f"chunk-{i}",
                "text": paragraph,
                "start": start,
                "end": end
            })
            current_pos = end
    
    return chunks

def test_old_approach(chunks: List[Dict], full_text: str, topic: str):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞—Ä—ã–π –ø–æ–¥—Ö–æ–¥ (–º–Ω–æ–∂–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤)"""
    
    print("\n" + "="*60)
    print("–°–¢–ê–†–´–ô –ü–û–î–•–û–î (–º–Ω–æ–∂–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤)")
    print("="*60)
    
    endpoint = f"{API_BASE}/api/v1/hybrid/chunks/metrics/semantic-batch"
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    chunks_data = [{"id": c["id"], "text": c["text"]} for c in chunks]
    
    payload = {
        "chunks": chunks_data,
        "full_text": full_text,
        "topic": topic
    }
    
    start_time = time.time()
    
    try:
        response = requests.post(
            endpoint, 
            json=payload,
            params={"prefer_realtime": "false"}  # –ò—Å–ø–æ–ª—å–∑—É–µ–º REST –¥–ª—è —á–µ—Å—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        )
        response.raise_for_status()
        
        elapsed = time.time() - start_time
        data = response.json()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        successful = len([r for r in data["results"] if r["metrics"].get("semantic_function")])
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}/{len(chunks)} —á–∞–Ω–∫–æ–≤")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è: {elapsed:.2f} —Å–µ–∫")
        print(f"üì° –ó–∞–ø—Ä–æ—Å–æ–≤ –∫ API: {len(chunks)}")
        print(f"üí∞ –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: ~{len(full_text) * len(chunks) // 4}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüîç –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏:")
        for result in data["results"]:
            func = result["metrics"].get("semantic_function", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            print(f"  {result['chunk_id']}: {func}")
            
        return elapsed, successful
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return None, 0

def test_new_approach(chunks: List[Dict], full_text: str, topic: str):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (–æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å)"""
    
    print("\n" + "="*60)
    print("–ù–û–í–´–ô –ü–û–î–•–û–î (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)")
    print("="*60)
    
    endpoint = f"{API_BASE}/api/v2/optimized/semantic/batch"
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏
    boundaries = [
        {"chunk_id": c["id"], "start": c["start"], "end": c["end"]} 
        for c in chunks
    ]
    
    payload = {
        "full_text": full_text,
        "chunk_boundaries": boundaries,
        "topic": topic
    }
    
    start_time = time.time()
    
    try:
        response = requests.post(endpoint, json=payload)
        response.raise_for_status()
        
        elapsed = time.time() - start_time
        data = response.json()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        successful = len([r for r in data["results"] if r["metrics"].get("semantic_function")])
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}/{len(chunks)} —á–∞–Ω–∫–æ–≤")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è: {elapsed:.2f} —Å–µ–∫")
        print(f"üì° –ó–∞–ø—Ä–æ—Å–æ–≤ –∫ API: {data.get('requests_count', 1)}")
        print(f"üí∞ –°—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: ~{data.get('tokens_saved', 0)}")
        print(f"üöÄ –ú–µ—Ç–æ–¥: {data.get('method', 'unknown')}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüîç –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏:")
        for result in data["results"]:
            func = result["metrics"].get("semantic_function", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            print(f"  {result['chunk_id']}: {func}")
            
        return elapsed, successful
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        if hasattr(e, 'response') and e.response:
            print(f"–î–µ—Ç–∞–ª–∏: {e.response.text}")
        return None, 0

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    print("üß™ –°–†–ê–í–ù–ï–ù–ò–ï –ü–û–î–•–û–î–û–í –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –ê–ù–ê–õ–ò–ó–ê")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏
    chunks = create_test_chunks(TEST_TEXT)
    print(f"\nüìÑ –¢–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç:")
    print(f"  –†–∞–∑–º–µ—Ä: {len(TEST_TEXT)} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"  –ß–∞–Ω–∫–æ–≤: {len(chunks)}")
    print(f"  –¢–µ–º–∞: '–ö–æ—Ä–æ–≤—ã'")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–π –ø–æ–¥—Ö–æ–¥
    old_time, old_success = test_old_approach(chunks, TEST_TEXT, "–ö–æ—Ä–æ–≤—ã")
    
    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
    print("\n‚è∏Ô∏è –ü–∞—É–∑–∞ 5 —Å–µ–∫—É–Ω–¥...")
    time.sleep(5)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥
    new_time, new_success = test_new_approach(chunks, TEST_TEXT, "–ö–æ—Ä–æ–≤—ã")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "="*60)
    print("üìà –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("="*60)
    
    if old_time and new_time:
        speedup = old_time / new_time
        print(f"\n‚ö° –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.1f}x")
        print(f"üïê –≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏: {old_time - new_time:.2f} —Å–µ–∫")
        print(f"üìâ –°–Ω–∏–∂–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏: {len(chunks)}‚Üí1 –∑–∞–ø—Ä–æ—Å ({len(chunks)}x –º–µ–Ω—å—à–µ)")
        
        # –û—Ü–µ–Ω–∫–∞ —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
        old_tokens = len(TEST_TEXT) * len(chunks) // 4
        new_tokens = len(TEST_TEXT) // 4 + 500
        token_savings = ((old_tokens - new_tokens) / old_tokens) * 100
        print(f"üí∞ –≠–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤: ~{token_savings:.0f}%")
        
        print("\n‚ú® –í–´–í–û–î:")
        print(f"–ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –≤ {speedup:.1f} —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ –∏ —ç–∫–æ–Ω–æ–º–∏—Ç ~{token_savings:.0f}% —Ç–æ–∫–µ–Ω–æ–≤!")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ")

if __name__ == "__main__":
    main() 