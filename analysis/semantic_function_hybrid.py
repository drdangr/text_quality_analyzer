"""
–ì–∏–±—Ä–∏–¥–Ω—ã–π –º–æ–¥—É–ª—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Realtime API –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ REST API –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö.
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import time

from .semantic_function import analyze_batch_chunks_semantic
from .semantic_function_realtime import SemanticRealtimeAnalyzer, RealtimeSessionConfig
from services.openai_service import OpenAIService

logger = logging.getLogger(__name__)


class APIMethod(Enum):
    """–ú–µ—Ç–æ–¥—ã API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    REALTIME = "realtime"
    REST = "rest"


@dataclass
class FailureTracker:
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è"""
    realtime_failures: int = 0
    realtime_successes: int = 0
    last_failure_time: Optional[datetime] = None
    failure_threshold: int = 3
    recovery_timeout: timedelta = field(default_factory=lambda: timedelta(minutes=5))
    
    def record_failure(self):
        """–ó–∞–ø–∏—Å–∞—Ç—å –æ—à–∏–±–∫—É Realtime API"""
        self.realtime_failures += 1
        self.last_failure_time = datetime.now()
        
    def record_success(self):
        """–ó–∞–ø–∏—Å–∞—Ç—å —É—Å–ø–µ—à–Ω—ã–π –≤—ã–∑–æ–≤ Realtime API"""
        self.realtime_successes += 1
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –ø–æ—Å–ª–µ —Å–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–æ–≤
        if self.realtime_successes > 5:
            self.realtime_failures = max(0, self.realtime_failures - 1)
            
    def should_use_realtime(self) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å—Ç–æ–∏—Ç –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Realtime API"""
        # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫
        if self.realtime_failures >= self.failure_threshold:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–ª–æ –ª–∏ –≤—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
            if self.last_failure_time:
                if datetime.now() - self.last_failure_time > self.recovery_timeout:
                    # –î–∞–µ–º –µ—â–µ –æ–¥–∏–Ω —à–∞–Ω—Å
                    self.realtime_failures = 0
                    self.realtime_successes = 0
                    return True
            return False
        return True


class HybridSemanticAnalyzer:
    """–ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º –º–µ–∂–¥—É API"""
    
    # –û—à–∏–±–∫–∏, –ø—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ REST API
    FALLBACK_ERRORS = {
        "Conversation already has an active response",
        "WebSocket connection closed",
        "Session not initialized",
        "Response timeout",
        "Invalid session state"
    }
    
    def __init__(self, api_key: str, prefer_realtime: bool = True):
        self.api_key = api_key
        self.prefer_realtime = prefer_realtime
        self.openai_service = OpenAIService(api_key=api_key)
        self.realtime_analyzer: Optional[SemanticRealtimeAnalyzer] = None
        self.failure_tracker = FailureTracker()
        self._realtime_session_active = False
        self._current_topic: Optional[str] = None
        
    async def _ensure_realtime_session(self, topic: str) -> bool:
        """–£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–µ—Å—Å–∏—è Realtime API –∞–∫—Ç–∏–≤–Ω–∞"""
        try:
            # –ï—Å–ª–∏ —Ç–µ–º–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å, –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
            if self._current_topic != topic:
                if self.realtime_analyzer:
                    await self.realtime_analyzer.close()
                    self._realtime_session_active = False
                    
            if not self._realtime_session_active:
                self.realtime_analyzer = SemanticRealtimeAnalyzer(api_key=self.api_key)
                await self.realtime_analyzer.connect()
                
                config = RealtimeSessionConfig(
                    topic=topic,
                    temperature=0.6
                )
                await self.realtime_analyzer.initialize_session(config)
                
                self._realtime_session_active = True
                self._current_topic = topic
                logger.info("Realtime API —Å–µ—Å—Å–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                
            return True
            
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Realtime API: {e}")
            self._realtime_session_active = False
            return False
    
    def _should_fallback(self, error: Exception) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ REST API"""
        error_str = str(error)
        return any(err in error_str for err in self.FALLBACK_ERRORS)
    
    async def analyze_chunk(
        self,
        chunk_id: str,
        chunk_text: str,
        topic: str,
        force_method: Optional[APIMethod] = None
    ) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω —á–∞–Ω–∫ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback.
        
        Args:
            chunk_id: ID —á–∞–Ω–∫–∞
            chunk_text: –¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞
            topic: –¢–µ–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            force_method: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–∫–∞–∑–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–º –º–µ—Ç–æ–¥–µ
        """
        start_time = time.time()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥
        if force_method:
            use_realtime = force_method == APIMethod.REALTIME
        else:
            use_realtime = self.prefer_realtime and self.failure_tracker.should_use_realtime()
        
        if use_realtime:
            logger.info(f"[Hybrid] üöÄ –ß–∞–Ω–∫ {chunk_id}: –ø—Ä–æ–±—É–µ–º Realtime API")
            try:
                # –ü—Ä–æ–±—É–µ–º Realtime API
                if not self._realtime_session_active:
                    await self._ensure_realtime_session(topic)
                
                if self.realtime_analyzer:
                    result = await self.realtime_analyzer.analyze_chunk(
                        chunk_id, chunk_text
                    )
                    self.failure_tracker.record_success()
                    result["api_method"] = APIMethod.REALTIME.value
                    result["api_latency"] = time.time() - start_time
                    logger.info(f"[Hybrid] ‚úÖ –ß–∞–Ω–∫ {chunk_id}: Realtime —É—Å–ø–µ—à–Ω–æ –∑–∞ {result['api_latency']:.2f}—Å")
                    return result
                else:
                    raise Exception("Realtime analyzer not initialized")
                
            except Exception as e:
                self.failure_tracker.record_failure()
                logger.warning(f"[Hybrid] ‚ö†Ô∏è –ß–∞–Ω–∫ {chunk_id}: Realtime –æ—à–∏–±–∫–∞: {str(e)[:100]}, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ REST")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ—Ä–∞ –ª–∏ –æ—Ç–∫–ª—é—á–∏—Ç—å Realtime
                if self.failure_tracker.realtime_failures >= 3:
                    logger.warning(f"[Hybrid] ‚ùå Realtime API –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω –ø–æ—Å–ª–µ {self.failure_tracker.realtime_failures} –æ—à–∏–±–æ–∫")
                    self._realtime_session_active = False
                    if self.realtime_analyzer:
                        await self.realtime_analyzer.close()
        else:
            logger.info(f"[Hybrid] üì° –ß–∞–Ω–∫ {chunk_id}: –∏—Å–ø–æ–ª—å–∑—É–µ–º REST API (Realtime {'–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω' if not self.failure_tracker.should_use_realtime() else '–Ω–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª–µ–Ω'})")
        
        # Fallback –Ω–∞ REST API
        try:
            logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º REST API –¥–ª—è —á–∞–Ω–∫–∞ {chunk_id}")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è REST API
            chunks = [{"id": chunk_id, "text": chunk_text}]
            
            # –í—ã–∑—ã–≤–∞–µ–º REST API
            results = await analyze_batch_chunks_semantic(
                chunks=chunks,
                full_text=chunk_text,  # –î–ª—è –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∂–µ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                topic=topic,
                openai_service=self.openai_service,
                max_parallel=1
            )
            
            if results and len(results) > 0:
                result = results[0]
                metrics = result.get("metrics", {})
                
                return {
                    "chunk_id": chunk_id,
                    "semantic_function": metrics.get("semantic_function"),
                    "semantic_method": metrics.get("semantic_method"),
                    "semantic_error": metrics.get("semantic_error"),
                    "api_method": APIMethod.REST.value,
                    "api_latency": time.time() - start_time
                }
            else:
                raise Exception("REST API –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                
        except Exception as e:
            logger.error(f"[Hybrid] ‚ùå –ß–∞–Ω–∫ {chunk_id}: REST —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
            return {
                "chunk_id": chunk_id,
                "semantic_function": None,
                "semantic_error": f"Both APIs failed: {str(e)[:150]}",
                "api_method": "failed",
                "api_latency": time.time() - start_time
            }
    
    async def analyze_batch(
        self,
        chunks: List[Dict[str, str]],
        topic: str,
        max_concurrent: int = 5,
        adaptive_batching: bool = True
    ) -> List[Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞–∫–µ—Ç —á–∞–Ω–∫–æ–≤ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π.
        
        Args:
            chunks: –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            topic: –¢–µ–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞  
            max_concurrent: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            adaptive_batching: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –±–∞—Ç—á–∏–Ω–≥–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        """
        logger.info(f"[HybridBatch] üéØ –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ {len(chunks)} —á–∞–Ω–∫–æ–≤. Adaptive={adaptive_batching}, MaxConcurrent={max_concurrent}")
        results = []
        
        if adaptive_batching and len(chunks) > 10 and self.failure_tracker.should_use_realtime():
            # –î–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥:
            # –ü–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤ —á–µ—Ä–µ–∑ Realtime –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ —á–µ—Ä–µ–∑ REST API –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            
            realtime_batch_size = min(5, len(chunks) // 4)
            
            logger.info(f"–ì–∏–±—Ä–∏–¥–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {realtime_batch_size} —á–µ—Ä–µ–∑ Realtime, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —á–µ—Ä–µ–∑ REST")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å —á–µ—Ä–µ–∑ Realtime
            realtime_chunks = chunks[:realtime_batch_size]
            rest_chunks = chunks[realtime_batch_size:]
            
            # Realtime –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, —Å –ø–∞—É–∑–∞–º–∏)
            for chunk in realtime_chunks:
                result = await self.analyze_chunk(
                    chunk_id=chunk["id"],
                    chunk_text=chunk["text"],
                    topic=topic,
                    force_method=APIMethod.REALTIME
                )
                results.append(result)
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ Realtime API
                if len(realtime_chunks) > 1:
                    await asyncio.sleep(0.5)
            
            # REST –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
            if rest_chunks:
                rest_results = await analyze_batch_chunks_semantic(
                    chunks=rest_chunks,
                    full_text="\n\n".join([c["text"] for c in chunks]),
                    topic=topic,
                    openai_service=self.openai_service,
                    max_parallel=max_concurrent
                )
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                for chunk, result in zip(rest_chunks, rest_results):
                    metrics = result.get("metrics", {})
                    results.append({
                        "chunk_id": chunk["id"],
                        "semantic_function": metrics.get("semantic_function"),
                        "semantic_method": metrics.get("semantic_method"),
                        "semantic_error": metrics.get("semantic_error"),
                        "api_method": APIMethod.REST.value,
                        "api_latency": 0
                    })
        else:
            # –î–ª—è –º–∞–ª—ã—Ö –æ–±—ä–µ–º–æ–≤ –∏–ª–∏ –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–Ω–æ–º Realtime –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥
            for chunk in chunks:
                result = await self.analyze_chunk(
                    chunk_id=chunk["id"],
                    chunk_text=chunk["text"],
                    topic=topic
                )
                results.append(result)
                
                # –ü–∞—É–∑–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è Realtime API
                if result.get("api_method") == APIMethod.REALTIME.value and len(chunks) > 1:
                    await asyncio.sleep(0.5)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        realtime_count = sum(1 for r in results if r.get("api_method") == APIMethod.REALTIME.value)
        rest_count = sum(1 for r in results if r.get("api_method") == APIMethod.REST.value)
        failed_count = sum(1 for r in results if r.get("api_method") == "failed")
        
        logger.info(
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤: "
            f"{realtime_count} —á–µ—Ä–µ–∑ Realtime, {rest_count} —á–µ—Ä–µ–∑ REST, {failed_count} –æ—à–∏–±–æ–∫"
        )
        
        return results
    
    async def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API"""
        return {
            "realtime_available": self.failure_tracker.should_use_realtime(),
            "realtime_failures": self.failure_tracker.realtime_failures,
            "realtime_successes": self.failure_tracker.realtime_successes,
            "last_failure": self.failure_tracker.last_failure_time.isoformat() if self.failure_tracker.last_failure_time else None,
            "session_active": self._realtime_session_active,
            "current_topic": self._current_topic
        }
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        if self.realtime_analyzer:
            await self.realtime_analyzer.close()
            self._realtime_session_active = False


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
async def analyze_semantic_hybrid(
    chunks: List[Dict[str, str]],
    topic: str,
    api_key: str,
    prefer_realtime: bool = True,
    **kwargs
) -> List[Dict[str, Any]]:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
    
    Args:
        chunks: –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        topic: –¢–µ–º–∞ —Ç–µ–∫—Å—Ç–∞
        api_key: –ö–ª—é—á OpenAI API
        prefer_realtime: –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞—Ç—å Realtime API (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è analyze_batch
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
    """
    analyzer = HybridSemanticAnalyzer(api_key=api_key, prefer_realtime=prefer_realtime)
    try:
        return await analyzer.analyze_batch(chunks, topic, **kwargs)
    finally:
        await analyzer.close() 