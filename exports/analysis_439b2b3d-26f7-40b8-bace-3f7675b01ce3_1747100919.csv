paragraph_id,text,lix,smog,complexity,signal_strength,semantic_function,semantic_method,semantic_error
0,"Это совершенно новый текст для первого абзаца, который мы обновляем инкрементально.",56.455,17.122,0.706,0.794,шум,api,
1,"Токенизация это процесс разбиения текста на мелкие части, называемые токенами. Это помогает в анализе.",60.346,13.817,0.754,0.8,раскрытие темы,api,
2,Чанкинг делит большие тексты на части поменьше. Это нужно для моделей с лимитом токенов.,52.654,12.162,0.658,0.802,раскрытие темы,api,
