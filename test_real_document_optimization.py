#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —á–∞–Ω–∫–æ–≤
"""

import requests
import json
import time
from typing import List, Dict

API_BASE = "http://localhost:8000"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª—å—à–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
def create_large_document(num_paragraphs: int = 23) -> str:
    """–°–æ–∑–¥–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∞–±–∑–∞—Ü–µ–≤"""
    
    templates = [
        "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É–µ—Ç {–æ–±–ª–∞—Å—Ç—å}. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç {–¥–µ–π—Å—Ç–≤–∏–µ}.",
        "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - —ç—Ç–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª –ò–ò, –∫–æ—Ç–æ—Ä—ã–π —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ {–∞—Å–ø–µ–∫—Ç}. –ê–ª–≥–æ—Ä–∏—Ç–º—ã —Å–ø–æ—Å–æ–±–Ω—ã {–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å}.",
        "–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏–º–∏—Ç–∏—Ä—É—é—Ç —Ä–∞–±–æ—Ç—É —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –º–æ–∑–≥–∞ –¥–ª—è {—Ü–µ–ª—å}. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç {—Ä–µ–∑—É–ª—å—Ç–∞—Ç}.",
        "–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è {–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ}. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–ø–µ—á–∞—Ç–ª—è—é—Ç –≤ –æ–±–ª–∞—Å—Ç–∏ {—Å—Ñ–µ—Ä–∞}.",
        "–û–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –ø–æ–º–æ–≥–∞–µ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º –ø–æ–Ω–∏–º–∞—Ç—å {—á—Ç–æ}. –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è {–∑–∞—á–µ–º}.",
    ]
    
    areas = ["–º–µ–¥–∏—Ü–∏–Ω—É", "–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ", "—Ñ–∏–Ω–∞–Ω—Å—ã", "—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç", "–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ"]
    actions = ["–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã", "—É–ª—É—á—à–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —É—Å–ª—É–≥", "–ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", "–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞—Ç—Ä–∞—Ç—ã"]
    aspects = ["—Å–æ–∑–¥–∞–Ω–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤", "–∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö", "—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤", "–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏"]
    
    paragraphs = []
    for i in range(num_paragraphs):
        template = templates[i % len(templates)]
        paragraph = template.format(
            –æ–±–ª–∞—Å—Ç—å=areas[i % len(areas)],
            –¥–µ–π—Å—Ç–≤–∏–µ=actions[i % len(actions)],
            –∞—Å–ø–µ–∫—Ç=aspects[i % len(aspects)],
            –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å="–æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö",
            —Ü–µ–ª—å="—Ä–µ—à–µ–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á",
            —Ä–µ–∑—É–ª—å—Ç–∞—Ç="–¥–æ—Å—Ç–∏–≥–∞—Ç—å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è —Ç–æ—á–Ω–æ—Å—Ç–∏",
            –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ="–∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
            —Å—Ñ–µ—Ä–∞="–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è",
            —á—Ç–æ="—á–µ–ª–æ–≤–µ—á–µ—Å–∫—É—é —Ä–µ—á—å",
            –∑–∞—á–µ–º="–≥–æ–ª–æ—Å–æ–≤—ã—Ö –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤"
        )
        paragraphs.append(f"–ü–∞—Ä–∞–≥—Ä–∞—Ñ {i+1}. {paragraph}")
    
    return "\n\n".join(paragraphs)

def create_chunks_from_text(text: str) -> List[Dict]:
    """–°–æ–∑–¥–∞–µ—Ç —á–∞–Ω–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    chunks = []
    paragraphs = text.split('\n\n')
    current_pos = 0
    
    for i, paragraph in enumerate(paragraphs):
        if paragraph.strip():
            start = text.find(paragraph, current_pos)
            end = start + len(paragraph)
            chunks.append({
                "id": f"chunk-{i}",
                "text": paragraph,
                "start": start,
                "end": end
            })
            current_pos = end
    
    return chunks

def test_new_optimized_api(chunks: List[Dict], full_text: str, topic: str):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π API"""
    
    print(f"\nüöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û API")
    print("=" * 60)
    
    endpoint = f"{API_BASE}/api/v2/optimized/semantic/batch"
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —á–∞–Ω–∫–æ–≤
    boundaries = [
        {"chunk_id": c["id"], "start": c["start"], "end": c["end"]} 
        for c in chunks
    ]
    
    payload = {
        "full_text": full_text,
        "chunk_boundaries": boundaries,
        "topic": topic
    }
    
    start_time = time.time()
    
    try:
        response = requests.post(endpoint, json=payload)
        response.raise_for_status()
        
        elapsed = time.time() - start_time
        data = response.json()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        successful = len([r for r in data["results"] if r["metrics"].get("semantic_function")])
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {successful}/{len(chunks)} —á–∞–Ω–∫–æ–≤")
        print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {elapsed:.2f} —Å–µ–∫")
        print(f"‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —á–∞–Ω–∫: {elapsed/len(chunks):.3f} —Å–µ–∫")
        print(f"üì° –ó–∞–ø—Ä–æ—Å–æ–≤ –∫ API: {data.get('requests_count', 1)}")
        print(f"üí∞ –°—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: ~{data.get('tokens_saved', 0):,}")
        
        # –û—Ü–µ–Ω–∫–∞ —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å–æ —Å—Ç–∞—Ä—ã–º –ø–æ–¥—Ö–æ–¥–æ–º
        estimated_old_time = len(chunks) * 1.4  # ~1.4 —Å–µ–∫ –Ω–∞ —á–∞–Ω–∫ –≤ —Å—Ç–∞—Ä–æ–º –ø–æ–¥—Ö–æ–¥–µ
        time_saved = estimated_old_time - elapsed
        speedup = estimated_old_time / elapsed if elapsed > 0 else 0
        
        print(f"\nüìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º:")
        print(f"   –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è —Å—Ç–∞—Ä–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞: ~{estimated_old_time:.1f} —Å–µ–∫")
        print(f"   –≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏: {time_saved:.1f} —Å–µ–∫")
        print(f"   –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.1f}x")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüîç –ü—Ä–∏–º–µ—Ä—ã —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π (–ø–µ—Ä–≤—ã–µ 5):")
        for i, result in enumerate(data["results"][:5]):
            func = result["metrics"].get("semantic_function", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            print(f"   {result['chunk_id']}: {func}")
        
        if len(data["results"]) > 5:
            print(f"   ... –∏ –µ—â–µ {len(data["results"]) - 5} —á–∞–Ω–∫–æ–≤")
            
        return elapsed, successful
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        if hasattr(e, 'response') and e.response:
            print(f"–î–µ—Ç–∞–ª–∏: {e.response.text[:500]}")
        return None, 0

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üß™ –¢–ï–°–¢ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò –ù–ê –†–ï–ê–õ–¨–ù–û–ú –î–û–ö–£–ú–ï–ù–¢–ï")
    print("=" * 60)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    test_sizes = [10, 23, 50]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
    
    for num_chunks in test_sizes:
        # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        document = create_large_document(num_chunks)
        chunks = create_chunks_from_text(document)
        
        print(f"\n\nüìÑ –î–æ–∫—É–º–µ–Ω—Ç #{num_chunks}:")
        print(f"   –†–∞–∑–º–µ—Ä: {len(document):,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ß–∞–Ω–∫–æ–≤: {len(chunks)}")
        print(f"   –¢–µ–º–∞: '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç'")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º
        test_new_optimized_api(chunks, document, "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç")
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
        if num_chunks < test_sizes[-1]:
            print("\n‚è∏Ô∏è –ü–∞—É–∑–∞ 3 —Å–µ–∫—É–Ω–¥—ã...")
            time.sleep(3)
    
    print("\n\n" + "="*60)
    print("‚úÖ –í–´–í–û–î–´:")
    print("- –ß–µ–º –±–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç, —Ç–µ–º –±–æ–ª—å—à–µ –≤—ã–≥–æ–¥–∞ –æ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    print("- –≠–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∏–≥–∞—Ç—å 90%+ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print("- –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    print("- –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å rate limiting")

if __name__ == "__main__":
    main() 